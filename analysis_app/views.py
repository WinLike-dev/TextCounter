# analysis_app/views.py

from django.shortcuts import render, redirect
from django.urls import reverse
from wordcloud import WordCloud
import io
import base64
from typing import List, Tuple, Optional, Dict, Any
from data_processor.cache_manager import get_top_nouns_for_conditions
from data_processor.importer import run_extraction_and_save_to_category_nouns
from data_processor.constants import TOP_N


def generate_word_cloud_image(word_counts: List[Dict[str, int]]) -> Optional[str]:
    """WordCloud ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê³  base64 ë¬¸ìì—´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤. (dict í˜•ì‹ì— ë§ê²Œ ìˆ˜ì •)"""
    word_freq_dict = {item['word']: item['count'] for item in word_counts}
    if not word_freq_dict: return None

    # ğŸ’¡ [ìˆ˜ì •] í°íŠ¸ ê²½ë¡œë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  WordCloudë¥¼ ìƒì„±í•˜ì—¬ OSError ë°©ì§€
    # í°íŠ¸ ê²½ë¡œë¥¼ ì°¾ì§€ ëª»í•˜ì—¬ 'OSError: cannot open resource'ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.
    # í•´ë‹¹ ë¶€ë¶„ì„ ì œê±°í•˜ì—¬ WordCloudê°€ ì‹œìŠ¤í…œ ê¸°ë³¸ í°íŠ¸ë¥¼ ì‚¬ìš©í•˜ë„ë¡ í•©ë‹ˆë‹¤.
    # try:
    #     font_path = 'static/malgun.ttf'
    #     wc = WordCloud(
    #         background_color="white",
    #         width=800, height=400, max_words=len(word_freq_dict),
    #         font_path=font_path
    #     )
    # except ValueError:
    #     # í°íŠ¸ê°€ ì—†ì„ ê²½ìš° ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©
    #     wc = WordCloud(
    #         background_color="white",
    #         width=800, height=400, max_words=len(word_freq_dict)
    #     )

    # í°íŠ¸ ì„¤ì • ì—†ì´ WordCloud ê°ì²´ ìƒì„±
    wc = WordCloud(
        background_color="white",
        width=800, height=400, max_words=len(word_freq_dict)
    )

    wc.generate_from_frequencies(word_freq_dict)

    img_io = io.BytesIO()
    wc.to_image().save(img_io, format='PNG')
    img_io.seek(0)

    return 'data:image/png;base64,' + base64.b64encode(img_io.read()).decode()


def index(request):
    """ë©”ì¸ í˜ì´ì§€ ë·°"""
    success_message = request.session.pop('success_message', None)
    return render(request, 'analysis_app/index.html', {'success_message': success_message, 'TOP_N': TOP_N})


def rebuild_imfiles_view(request):
    """DB ë°ì´í„° ì¬ìƒì„± ìš”ì²­ ì²˜ë¦¬ ë·°"""
    if request.method == 'POST':
        try:
            run_extraction_and_save_to_category_nouns()
            request.session['success_message'] = "âœ… ImFiles ë°ì´í„°(file_noun_records) ì¬ìƒì„± ì™„ë£Œ!"
        except Exception as e:
            return render(request, 'analysis_app/error.html', {
                'message': f'ë°ì´í„° ì¬ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}'
            }, status=500)

    return redirect(reverse('index'))


def wordcloud_view(request):
    """
    WordCloud í‘œì‹œ ë·°: GET ì¿¼ë¦¬ ë§¤ê°œë³€ìˆ˜ë¥¼ ë°›ì•„ ì¡°ê±´ë¶€ ì›Œë“œí´ë¼ìš°ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """

    # 1. ì¿¼ë¦¬ ë§¤ê°œë³€ìˆ˜ ì¶”ì¶œ
    title = request.GET.get('title')
    tags_input = request.GET.get('tags')
    start_date = request.GET.get('start_date')
    end_date = request.GET.get('end_date')
    top_n = request.GET.get('top_n', TOP_N)

    try:
        top_n = int(top_n)
    except ValueError:
        top_n = TOP_N

    # tags_inputì„ ì‰¼í‘œë¡œ ë¶„ë¦¬í•˜ê³  ê³µë°±ì„ ì œê±°í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“¦
    parsed_tags = [tag.strip() for tag in tags_input.split(',') if tag.strip()] if tags_input else None

    # 2. ì¿¼ë¦¬ ê°ì²´(ë”•ì…”ë„ˆë¦¬) êµ¬ì„±
    query_conditions: Dict[str, Any] = {
        'title': title,
        'tags': parsed_tags,
        'start_date': start_date,
        'end_date': end_date,
    }

    # ğŸ’¡ [ì´ì „ ìš”ì²­ì— ë”°ë¼ ì œê±°ë¨] ìœ íš¨ì„± ê²€ì‚¬ ë¡œì§ ì‚­ì œ: ì¡°ê±´ì´ ì—†ì–´ë„ ì „ì²´ ë¶„ì„ì„ ìœ„í•´ ì§„í–‰í•©ë‹ˆë‹¤.
    # if not (title or parsed_tags or start_date or end_date):
    #     return render(request, 'analysis_app/error.html', {
    #         'message': 'Title, Tags, Start Date, End Date ì¤‘ ìµœì†Œí•œ í•˜ë‚˜ëŠ” ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.'
    #     }, status=400)

    # 3. cache_managerë¥¼ í†µí•´ ì¡°ê±´ë¶€ ëª…ì‚¬ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ê°ì²´ ì „ë‹¬)
    top_words_data = get_top_nouns_for_conditions(
        query_conditions=query_conditions,
        top_n=top_n
    )

    if top_words_data is None:
        return render(request, 'analysis_app/error.html', {
            'message': 'ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”.'
        }, status=500)

    # 4. ë°ì´í„°ë¡œ ì›Œë“œí´ë¼ìš°ë“œ ì´ë¯¸ì§€ ìƒì„±
    image_base64 = generate_word_cloud_image(top_words_data)

    # 5. Context êµ¬ì„± ë° ë Œë”ë§
    context = {
        # ì¡°ê±´ì„ í…œí”Œë¦¿ì— ì „ë‹¬í•˜ì—¬ í‘œì‹œ
        'title': title or 'ì „ì²´',
        'tags': ', '.join(parsed_tags) if parsed_tags else 'ì „ì²´',
        'start_date': start_date or 'ì „ì²´',
        'end_date': end_date or 'ì „ì²´',
        'top_n': top_n,

        'image_base64': image_base64,
        'top_words': top_words_data,
    }

    return render(request, 'analysis_app/wordcloud.html', context)