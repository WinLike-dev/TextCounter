# data_processor/cache_manager.py

from typing import List, Dict, Optional, Any
from collections import Counter
from .db_connector import get_mongodb_client
# ë¶„ì‚° ì²˜ë¦¬ í•¨ìˆ˜ ì„í¬íŠ¸
from .master_connector import distribute_importer_rebuild
from .constants import (
    DB_NAME, RECORD_NOUNS_COLLECTION, TOP_NOUNS_CACHE_COLLECTION, TOP_N,
    DB_FIELD_HEADING, DB_FIELD_DATE, DB_FIELD_TAGS, DB_FIELD_NOUNS,
    CACHE_FIELD_TITLE_QUERY, CACHE_FIELD_START_DATE_QUERY, CACHE_FIELD_END_DATE_QUERY,
    CACHE_FIELD_TAGS_QUERY, CACHE_FIELD_TOP_N, CACHE_FIELD_TOP_WORDS
)


def get_top_nouns_from_cache(query_conditions: Dict[str, Any], top_n: int = TOP_N) -> Optional[
    List[Dict[str, Any]]]:
    """
    ì£¼ì–´ì§„ ì¡°ê±´ ë”•ì…”ë„ˆë¦¬ì™€ top_nì— í•´ë‹¹í•˜ëŠ” ê²°ê³¼ë¥¼ ìºì‹œ ì»¬ë ‰ì…˜ì—ì„œ ì¡°íšŒí•©ë‹ˆë‹¤.
    """
    client = get_mongodb_client()
    if not client: return None
    db = client[DB_NAME]
    cache_collection = db[TOP_NOUNS_CACHE_COLLECTION]

    title = query_conditions.get('title', "")
    tags = query_conditions.get('tags', None)
    start_date = query_conditions.get('start_date', "")
    end_date = query_conditions.get('end_date', "")

    # ìºì‹œ í‚¤ë¥¼ ìœ„í•œ ì •ê·œí™”ëœ íƒœê·¸ ë¬¸ìì—´ ìƒì„±
    tags_key = ",".join(tags) if tags else ""

    query = {
        CACHE_FIELD_TITLE_QUERY: title,
        CACHE_FIELD_TAGS_QUERY: tags_key,
        CACHE_FIELD_START_DATE_QUERY: start_date,
        CACHE_FIELD_END_DATE_QUERY: end_date,
        CACHE_FIELD_TOP_N: top_n
    }
    cached_doc = cache_collection.find_one(query)
    client.close()

    if cached_doc:
        print(f"âœ… ìºì‹œì—ì„œ ë°ì´í„°ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
        return cached_doc.get(CACHE_FIELD_TOP_WORDS)

    print("âŒ ìºì‹œì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
    return None


def calculate_and_save_top_nouns(query_conditions: Dict[str, Any], top_n: int = TOP_N) -> Optional[
    List[Dict[str, Any]]]:
    """
    'file_noun_records'ì—ì„œ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ë ˆì½”ë“œë¥¼ ê²€ìƒ‰í•˜ê³ ,
    ëª…ì‚¬ ë¹ˆë„ìˆ˜ë¥¼ ê³„ì‚°í•˜ì—¬ ìƒìœ„ Nê°œë¥¼ ìºì‹œì— ì €ì¥í•©ë‹ˆë‹¤.
    (ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì›Œì»¤ì— ì¬ì²˜ë¦¬ ëª…ë ¹ì„ ë‚´ë¦¬ê³  í•œ ë²ˆ ë” ì‹œë„í•©ë‹ˆë‹¤.)
    """
    client = get_mongodb_client()
    if not client: return None

    db = client[DB_NAME]
    record_collection = db[RECORD_NOUNS_COLLECTION]
    cache_collection = db[TOP_NOUNS_CACHE_COLLECTION]

    title = query_conditions.get('title', "")
    tags = query_conditions.get('tags', None)
    start_date = query_conditions.get('start_date', "")
    end_date = query_conditions.get('end_date', "")

    # 1. 'file_noun_records' ì»¬ë ‰ì…˜ì—ì„œ ì¡°ê±´ì— ë§ëŠ” ë¬¸ì„œ ê²€ìƒ‰ì„ ìœ„í•œ ì¿¼ë¦¬ ì„¤ì •
    query: Dict[str, Any] = {}

    # Title (Heading) ê²€ìƒ‰: ë¶€ë¶„ ì¼ì¹˜ ë° ëŒ€ì†Œë¬¸ì ë¬´ì‹œ (i)
    if title: query[DB_FIELD_HEADING] = {"$regex": title, "$options": "i"}

    # Tags ê²€ìƒ‰: ì£¼ì–´ì§„ íƒœê·¸ ë¦¬ìŠ¤íŠ¸ ì¤‘ í•˜ë‚˜ë¼ë„ í¬í•¨í•˜ëŠ” ë¬¸ì„œ ($in)
    if tags: query[DB_FIELD_TAGS] = {"$in": tags}

    # Date Range ê²€ìƒ‰
    date_query = {}
    if start_date: date_query["$gte"] = start_date
    if end_date: date_query["$lte"] = end_date
    if date_query: query[DB_FIELD_DATE] = date_query

    def fetch_records(collection) -> List[Dict[str, Any]]:
        """DBì—ì„œ ë ˆì½”ë“œë¥¼ ê°€ì ¸ì˜¤ëŠ” ë‚´ë¶€ í•¨ìˆ˜"""
        print(f"ğŸ” '{RECORD_NOUNS_COLLECTION}'ì—ì„œ ì¡°ê±´ ({query})ì— ë§ëŠ” ë ˆì½”ë“œ ê²€ìƒ‰ ì¤‘...")
        # í•„ìš”í•œ í•„ë“œ(ëª…ì‚¬ ë¦¬ìŠ¤íŠ¸)ë§Œ ê°€ì ¸ì™€ ë„¤íŠ¸ì›Œí¬ ë¶€í•˜ ì¤„ì´ê¸°
        return list(collection.find(query, {DB_FIELD_NOUNS: 1, "_id": 0}))

    # 1ì°¨ ê²€ìƒ‰
    matching_records = fetch_records(record_collection)

    # --- [ì‚¬ìš©ì ìš”ì²­ ë¡œì§: ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ì›Œì»¤ ì¬ì²˜ë¦¬ í›„ ì¬ì‹œë„] ---
    if not matching_records:
        print(f"âš ï¸ ê²½ê³ : 1ì°¨ ê²€ìƒ‰ì—ì„œ ì¡°ê±´ ({query})ì— ë§ëŠ” ë ˆì½”ë“œê°€ ì—†ìŠµë‹ˆë‹¤. (ê²€ìƒ‰ ì¡°ê±´ ë¯¸ì¼ì¹˜)")
        print("ğŸš€ ì›Œì»¤ë“¤ì—ê²Œ ë¶„ì‚° Importer ì¬ì²˜ë¦¬ ëª…ë ¹ì„ ìš”ì²­í•˜ê³  ì¬ì‹œë„í•©ë‹ˆë‹¤...")

        try:
            # 1. ì›Œì»¤ì—ê²Œ ì¬ì²˜ë¦¬ ëª…ë ¹ ìš”ì²­
            rebuild_result = distribute_importer_rebuild()
            print("âœ… ì›Œì»¤ ì¬ì²˜ë¦¬ ëª…ë ¹ ì™„ë£Œ. 2ì°¨ ê²€ìƒ‰ì„ ì‹œë„í•©ë‹ˆë‹¤.")

            # 2. 2ì°¨ ê²€ìƒ‰ ì‹œë„
            matching_records = fetch_records(record_collection)  # 2ì°¨ ê²€ìƒ‰

        except Exception as e:
            print(f"âŒ ì›Œì»¤ ì¬ì²˜ë¦¬ ëª…ë ¹ ì¤‘ ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ ë°œìƒ: {e}")

    if not matching_records:
        client.close()
        print(f"âš ï¸ ê²½ê³ : ìµœì¢…ì ìœ¼ë¡œ ì¡°ê±´ ({query})ì— ë§ëŠ” ë ˆì½”ë“œê°€ '{RECORD_NOUNS_COLLECTION}'ì— ì—†ìŠµë‹ˆë‹¤. (ê²€ìƒ‰ ì¡°ê±´ ë¯¸ì¼ì¹˜)")
        return []

    # 2. ëª…ì‚¬ ì¢…í•© ë° ë¹ˆë„ìˆ˜ ê³„ì‚°
    all_nouns = []
    for record in matching_records:
        all_nouns.extend(record.get(DB_FIELD_NOUNS, []))

    noun_counts = Counter(all_nouns)
    top_n_words = noun_counts.most_common(top_n)

    top_words_for_db = [{"word": word, "count": count} for word, count in top_n_words]

    # 3. ìƒˆë¡œìš´ MongoDB ì»¬ë ‰ì…˜ì— ì €ì¥ (ìºì‹œ)
    tags_key = ",".join(tags) if tags else ""
    cache_document = {
        CACHE_FIELD_TITLE_QUERY: title,
        CACHE_FIELD_TAGS_QUERY: tags_key,
        CACHE_FIELD_START_DATE_QUERY: start_date,
        CACHE_FIELD_END_DATE_QUERY: end_date,
        CACHE_FIELD_TOP_N: top_n,
        "total_records": len(matching_records),
        CACHE_FIELD_TOP_WORDS: top_words_for_db
    }
    # ìºì‹œ ë¬¸ì„œë¥¼ ìœ ì¼í•˜ê²Œ ì‹ë³„í•  ìˆ˜ ìˆëŠ” ì¿¼ë¦¬
    cache_query = {k: cache_document[k] for k in
                   [CACHE_FIELD_TITLE_QUERY, CACHE_FIELD_TAGS_QUERY, CACHE_FIELD_START_DATE_QUERY,
                    CACHE_FIELD_END_DATE_QUERY, CACHE_FIELD_TOP_N]}

    # Upsertë¥¼ ì‚¬ìš©í•˜ì—¬ ìºì‹œ ì¡´ì¬ ì‹œ ì—…ë°ì´íŠ¸, ì—†ìœ¼ë©´ ì‚½ì…
    cache_collection.replace_one(cache_query, cache_document, upsert=True)
    client.close()

    return top_words_for_db


def get_top_nouns_for_conditions(query_conditions: Dict[str, Any], top_n: int = TOP_N) -> Optional[
    List[Dict[str, Any]]]:
    """
    ë©”ì¸ ì§„ì… í•¨ìˆ˜: ìºì‹œ í™•ì¸ í›„, ì—†ìœ¼ë©´ ê³„ì‚° ë° ì €ì¥ í›„ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    (calculate_and_save_top_nouns ë‚´ë¶€ì—ì„œ ì¡°ê±´ ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ë¶„ì‚° ì¬ì²˜ë¦¬ê°€ ìë™ìœ¼ë¡œ ìˆ˜í–‰ë©ë‹ˆë‹¤.)
    """
    title = query_conditions.get('title')
    tags = query_conditions.get('tags')
    start_date = query_conditions.get('start_date')
    end_date = query_conditions.get('end_date')

    if not (title or tags or start_date or end_date):
        print("âŒ ì˜¤ë¥˜: Title, Tags, Start Date/End Date ì¤‘ ìµœì†Œí•œ í•˜ë‚˜ëŠ” ì…ë ¥ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.")
        return None

    tt = title if title is not None else ""
    tg = tags if tags is not None else None
    sd = start_date if start_date is not None else ""
    ed = end_date if end_date is not None else ""

    processed_conditions = {
        'title': tt, 'tags': tg, 'start_date': sd, 'end_date': ed,
    }

    # 1. ìºì‹œ í™•ì¸
    cached_result = get_top_nouns_from_cache(processed_conditions, top_n)
    if cached_result is not None:
        return cached_result

    # 2. ì¤‘ê°„ ë°ì´í„° DBì—ì„œ ê³„ì‚° ë° ì €ì¥
    print("âš ï¸ ìºì‹œ ë¯¸ìŠ¤. ì¤‘ê°„ ë°ì´í„° DBì—ì„œ ëª…ì‚¬ ì§‘ê³„ ë° ìºì‹œ ì €ì¥ ì‹œì‘...")

    # calculate_and_save_top_nouns ë‚´ë¶€ì—ì„œ 1ì°¨ ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ìë™ ì¬ì²˜ë¦¬ ë° 2ì°¨ ê²€ìƒ‰ì´ ì‹¤í–‰ë©ë‹ˆë‹¤.
    result = calculate_and_save_top_nouns(processed_conditions, top_n)

    return result